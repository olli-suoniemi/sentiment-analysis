{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/suonieo1/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read the data from the file. Rename the columns to \"Text\" and \"Sentiment\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('data.csv', delimiter=',', encoding='latin-1', header=None)\n",
    "df = df.rename(columns=lambda x: ['Sentiment', 'Text'][x])\n",
    "df = df[['Text', 'Sentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Tokenization (split the text into words)\n",
    "    words = nltk.word_tokenize(text)\n",
    "    \n",
    "    # Remove punctuation and convert to lowercase\n",
    "    words = [word.lower() for word in words if word.isalpha()]\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    \n",
    "    # Stemming (reducing words to their root form)\n",
    "    stemmer = PorterStemmer()\n",
    "    words = [stemmer.stem(word) for word in words]\n",
    "    \n",
    "    # Join the cleaned words back into a single string\n",
    "    cleaned_text = ' '.join(words)\n",
    "    \n",
    "    return cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                Text Sentiment\n",
      "0  accord gran compani plan move product russia a...   neutral\n",
      "1  technopoli plan develop stage area less squar ...   neutral\n",
      "2  intern electron industri compani elcoteq laid ...  negative\n",
      "3  new product plant compani would increas capac ...  positive\n",
      "4  accord compani updat strategi year baswar targ...  positive\n"
     ]
    }
   ],
   "source": [
    "# Apply preprocessing to each text in the DataFrame\n",
    "df['Text'] = df['Text'].apply(preprocess_text)\n",
    "\n",
    "# The 'Text' column now contains preprocessed text\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Validation Results:\n",
      "Accuracy: 0.7628865979381443\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.86      0.37      0.52        99\n",
      "     neutral       0.75      0.96      0.84       466\n",
      "    positive       0.80      0.52      0.63       211\n",
      "\n",
      "    accuracy                           0.76       776\n",
      "   macro avg       0.80      0.62      0.66       776\n",
      "weighted avg       0.78      0.76      0.74       776\n",
      "\n",
      "Multinomial Naive Bayes Validation Results:\n",
      "Accuracy: 0.6597938144329897\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       1.00      0.04      0.08        99\n",
      "     neutral       0.66      0.98      0.79       466\n",
      "    positive       0.62      0.25      0.35       211\n",
      "\n",
      "    accuracy                           0.66       776\n",
      "   macro avg       0.76      0.42      0.41       776\n",
      "weighted avg       0.69      0.66      0.58       776\n",
      "\n",
      "Logistic Regression Test Results:\n",
      "Accuracy: 0.7618556701030927\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.93      0.45      0.61       110\n",
      "     neutral       0.74      0.95      0.83       571\n",
      "    positive       0.78      0.51      0.62       289\n",
      "\n",
      "    accuracy                           0.76       970\n",
      "   macro avg       0.82      0.64      0.69       970\n",
      "weighted avg       0.78      0.76      0.74       970\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Split the data into train, validation, and test sets\n",
    "X = df['Text']\n",
    "y = df['Sentiment']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "# Feature extraction using TF-IDF\n",
    "tfidf_vectorizer = TfidfVectorizer(max_features=10000)  # You can adjust max_features as needed\n",
    "X_train_tfidf = tfidf_vectorizer.fit_transform(X_train)\n",
    "X_val_tfidf = tfidf_vectorizer.transform(X_val)\n",
    "X_test_tfidf = tfidf_vectorizer.transform(X_test)\n",
    "\n",
    "# Modeling: Implement the models mentioned in your paper\n",
    "# 1. Convolutional Neural Networks (CNNs) - You'll need a deep learning library like TensorFlow or PyTorch for this\n",
    "# 2. Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# 3. Other models (you can add more models as needed)\n",
    "# Example: Multinomial Naive Bayes\n",
    "nb_model = MultinomialNB()\n",
    "nb_model.fit(X_train_tfidf, y_train)\n",
    "\n",
    "# Evaluate models on the validation set\n",
    "y_val_pred_lr = lr_model.predict(X_val_tfidf)\n",
    "y_val_pred_nb = nb_model.predict(X_val_tfidf)\n",
    "\n",
    "# Print evaluation metrics\n",
    "print(\"Logistic Regression Validation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred_lr))\n",
    "print(classification_report(y_val, y_val_pred_lr))\n",
    "\n",
    "print(\"Multinomial Naive Bayes Validation Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_val, y_val_pred_nb))\n",
    "print(classification_report(y_val, y_val_pred_nb))\n",
    "\n",
    "# You can similarly evaluate the other models you mentioned in your paper\n",
    "\n",
    "# Once you've selected the best-performing model on the validation set, you can evaluate it on the test set\n",
    "# Example for Logistic Regression\n",
    "y_test_pred_lr = lr_model.predict(X_test_tfidf)\n",
    "print(\"Logistic Regression Test Results:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred_lr))\n",
    "print(classification_report(y_test, y_test_pred_lr))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
